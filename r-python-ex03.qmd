---
title: "r-python-ex3"
author: "Himanshu Nimbarte"
format: html
editor: visual
---

# **Classification: Basic Concepts and Techniques**

## **Install packages**

```{r message=FALSE, warning=FALSE}
if(!require(pacman))
  install.packages("pacman")

pacman::p_load(tidyverse, rpart, rpart.plot, caret, 
  lattice, FSelector, sampling, pROC, mlbench)
```

## **The Zoo Dataset**

To demonstrate classification, we will use the Zoo dataset which is included in the R package **mlbench** (you may have to install it). The Zoo dataset containing 17 (mostly logical) variables for 101 animals as a data frame with 17 columns (hair, feathers, eggs, milk, airborne, aquatic, predator, toothed, backbone, breathes, venomous, fins, legs, tail, domestic, catsize, type). The first 16 columns represent the feature vector � and the last column called type is the class label �. We convert the data frame into a tidyverse tibble (optional).

```{r}
data(Zoo)
head(Zoo)
```

In R, the **`tibble`** package provides a modern and user-friendly alternative to the traditional data frame. A **`tibble`** is a type of data structure introduced by the **`tibble`** package, and it's an enhanced version of the traditional data frame in R. Tibbles are part of the tidyverse ecosystem, and they have become popular due to their ease of use and consistent behavior.

```{r}
library(tidyverse)
as_tibble(Zoo, rownames = "animal")
```

```{r}
Zoo <- Zoo |>
  mutate(across(where(is.logical), factor, levels = c(TRUE, FALSE))) |>  #  converting logical columns to factors with "TRUE" and "FALSE" levels 
  
  mutate(across(where(is.character), factor))
```

```{r}
summary(Zoo)
```

## **Decision Trees**

Decision Trees are versatile supervised machine learning algorithms used for both classification and regression tasks. They work by recursively partitioning the data into subsets based on the values of input features. Each partition is based on a decision rule learned from the training data, enabling the algorithm to make predictions for unseen or future data points.

```{r}
library(rpart)
```

### **Create Tree With Default Settings (uses pre-pruning)**

**type \~** indicates that you want to predict the variable "type" using all other columns in the dataset (represented by the dot .).

```{r}
tree_default <- Zoo |> 
  rpart(type ~ ., data = _)
tree_default
```

Plotting

```{r warning=FALSE, message=FALSE}
library(rpart.plot)
rpart.plot(tree_default, extra = 2)
```

### **Create a Full Tree**

To create a full tree, we set the complexity parameter cp to 0 (split even if it does not improve the tree) and we set the minimum number of observations in a node needed to split to the smallest value of 2.

```{r}
tree_full <- Zoo |> 
  rpart(type ~ . , data = _, 
        control = rpart.control(minsplit = 2, cp = 0))
rpart.plot(tree_full, extra = 2, 
           roundint=FALSE,
            box.palette = list("Gy", "Gn", "Bu", "Bn", 
                               "Or", "Rd", "Pu")) # specify 7 colors
```

When **`cp`** is set to 0, it implies that no cost complexity pruning is utilized. In simpler terms, the tree is permitted to expand until it precisely matches the training data, potentially leading to an excessively intricate, deep, and overfitted tree.

```{r}
tree_full
```

Training error on tree with pre-pruning

```{r}
predict(tree_default, Zoo) |> head ()
```

```{r}
pred <- predict(tree_default, Zoo, type="class")
head(pred)
```

A confusion matrix is a performance measurement tool used in machine learning and classification tasks. It is used to evaluate the accuracy of a classification algorithm by summarizing the counts of true positive, true negative, false positive, and false negative predictions made by the model.

```{r}
confusion_table <- with(Zoo, table(type, pred))
confusion_table
```

```{r}
# Calculate the total number of correct predictions
correct <- confusion_table |> diag() |> sum()
correct
```

```{r}
# Calculate the total number of errors
error <- confusion_table |> sum() - correct
error
```

```{r}
accuracy <- correct / (correct + error)
accuracy
```

Use a function for accuracy

```{r}
accuracy <- function(truth, prediction) {
    tbl <- table(truth, prediction)
    sum(diag(tbl))/sum(tbl)
}

accuracy(Zoo |> pull(type), pred)
```

Training error of the full tree

```{r}
accuracy(Zoo |> pull(type), 
         predict(tree_full, Zoo, type = "class"))
```

```{r}
library(caret)
confusionMatrix(data = pred, 
                reference = Zoo |> pull(type))
```

### **Make Predictions for New Data**

Make up my own animal: A lion with feathered wings

```{r}
my_animal <- tibble(hair = TRUE, feathers = TRUE, eggs = FALSE,
  milk = TRUE, airborne = TRUE, aquatic = FALSE, predator = TRUE,
  toothed = TRUE, backbone = TRUE, breathes = TRUE, venomous = FALSE,
  fins = FALSE, legs = 4, tail = TRUE, domestic = FALSE,
  catsize = FALSE, type = NA)
```

Fix columns to be factors like in the training set.

```{r}
my_animal <- my_animal |> 
  mutate(across(where(is.logical), factor, levels = c(TRUE, FALSE)))
my_animal
```

Make a prediction using the default tree

```{r}
predict(tree_default , my_animal, type = "class")
```

## **Model Evaluation with Caret**

In R, the **`caret`** package provides a comprehensive framework for model training, tuning, and evaluation. It offers various functions and tools to streamline the process of building machine learning models.

```{r}
library(caret)
```

```{r}
set.seed(2000)
```

### **Hold out Test Data**

Test data is not used in the model building process and set aside purely for testing the model. Here, we partition data the 80% training and 20% testing.

```{r}
inTrain <- createDataPartition(y = Zoo$type, p = .8, list = FALSE)
Zoo_train <- Zoo |> slice(inTrain)
```

```{r}
Zoo_test <- Zoo |> slice(-inTrain)
```

### **Learn a Model and Tune Hyperparameters on the Training Data**

The **`caret`** package streamlines the process of tuning hyperparameters by integrating training and validation within a single function called **`train()`**. This function internally divides the data into training and validation sets, allowing you to assess the performance of different hyperparameter configurations. The **`trainControl`** function is employed to specify the testing approach.

In the context of the **`rpart`** model, **`train()`** optimizes the **`cp`** parameter (tree complexity) using accuracy as the criterion for selecting the best model. I've set **`minsplit`** to 2 due to the limited data available. It's essential to note that parameters intended for tuning, such as **`cp`** in this case, must be configured using a **`data.frame`** within the **`tuneGrid`** argument. Setting them within the **`control`** argument will be disregarded.

```{r}
fit <- Zoo_train |>
  train(type ~ .,
    data = _ ,
    method = "rpart",
    control = rpart.control(minsplit = 2),
    trControl = trainControl(method = "cv", number = 10),
    tuneLength = 5)

fit
```

In this case, the model with **cp = 0** was selected as the final model due to its perfect accuracy on the training data.

```{r}
rpart.plot(fit$finalModel, extra = 2,
  box.palette = list("Gy", "Gn", "Bu", "Bn", "Or", "Rd", "Pu"))
```

```{r}
varImp(fit)
```

**varImp** is a function from the **caret** package in R that is used to compute variable importance scores for a given machine learning model.

```{r}
imp <- varImp(fit, compete = FALSE)
imp
```

```{r}
ggplot(imp)
```

milkFalse has the highest importance score, represented as 100.00 and feathersFalse has an importance score of 55.69 , indicating it is also a significant pre

## **Testing: Confusion Matrix and Confidence Interval for Accuracy**

Use the best model on the test data

```{r}
pred <- predict(fit, newdata = Zoo_test)
pred
```

Caret's **confusionMatrix()** function calculates accuracy, confidence intervals, kappa and many more evaluation metrics. You need to use separate test data to create a confusion matrix based on the generalization error.

```{r}
confusionMatrix(data = pred, 
                ref = Zoo_test |> pull(type))
```

The **pull(type)** function is used to extract the actual values from the "type" column of the **Zoo_test** dataset.

The accuracy is 0.94 ,and Kappa is 0.92, indicating high performance model.

## **Model Comparison**

We will compare decision trees with a k-nearest neighbors (kNN) classifier. We will create fixed sampling scheme (10-folds) so we compare the different models using exactly the same folds. It is specified as `trControl` during training.

```{r}
train_index <- createFolds(Zoo_train$type, k = 10)
```

Build models:

1.  rpart

```{r}
rpartFit <- Zoo_train |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        tuneLength = 10,
        trControl = trainControl(method = "cv", indexOut = train_index)
  )
```

2.  KNN

```{r}
knnFit <- Zoo_train |> 
  train(type ~ .,
        data = _,
        method = "knn",
        preProcess = "scale",
          tuneLength = 10,
          trControl = trainControl(method = "cv", indexOut = train_index)
  )
```

Compare accuracy over all folds

```{r}
resamps <- resamples(list(
        CART = rpartFit,
        kNearestNeighbors = knnFit
        ))

summary(resamps)
```

```{r}
library(lattice)
bwplot(resamps, layout = c(3, 1))
```

We see that kNN is performing consistently better on the folds than CART (except for some outlier folds).

```{r}
difs <- diff(resamps)
difs
```

```{r}
summary(difs)
```

## **Feature Selection and Feature Preparation**

Feature selection is the process of choosing a subset of the most relevant and informative features (columns) from the dataset while discarding irrelevant or redundant ones. It's done to improve model performance and reduce the dimensionality of the dataset.

```{r}
library(FSelector)
```

```{r}
weights <- Zoo_train |> 
  chi.squared(type ~ ., data = _) |>
  as_tibble(rownames = "feature") |>
  arrange(desc(attr_importance))

weights
```

plot importance in descending order

```{r}
ggplot(weights,
  aes(x = attr_importance, y = reorder(feature, attr_importance))) +
  geom_bar(stat = "identity") +
  xlab("Importance score") + 
  ylab("Feature")
```

Get 5 best features

cutoff.k is used for selecting a specified number of top features based on their importance.

```{r}
subset <- cutoff.k(weights |> 
                   column_to_rownames("feature"), 5)
subset
```

kNearestNeighbors is performing better than CART.

Use only the best 5 features to build a model 

```{r}
f <- as.simple.formula(subset, "type") # function used to generate a formula in R
f
```

```{r}
m <- Zoo_train |> rpart(f, data = _)
rpart.plot(m, extra = 2, roundint = FALSE)
```

There are many alternative ways to calculate univariate importance scores (see package FSelector). Some of them (also) work for continuous features. One example is the information gain ratio based on entropy as used in decision tree induction.

```{r}
Zoo_train |> 
  gain.ratio(type ~ ., data = _) |>
  as_tibble(rownames = "feature") |>
  arrange(desc(attr_importance))
```

**gain.ratio** function calculates the gain ratio for each predictor variab

### **Feature Subset Selection**

Often features are related and calculating importance for each feature independently is not optimal. We can use greedy search heuristics.

```{r}
Zoo_train |> 
  cfs(type ~ ., data = _)
```

Black-box feature selection uses an evaluator function (the black box) to calculate a score to be maximized. First, we define an evaluation function that builds a model given a subset of features and calculates a quality score. We use here the average for 5 bootstrap samples (`method = "cv"` can also be used instead), no tuning (to be faster), and the average accuracy as the score.

```{r}
evaluator <- function(subset) {
  model <- Zoo_train |> 
    train(as.simple.formula(subset, "type"),
          data = _,
          method = "rpart",
          trControl = trainControl(method = "boot", number = 5),
          tuneLength = 0)
  results <- model$resample$Accuracy
  cat("Trying features:", paste(subset, collapse = " + "), "\n")
  m <- mean(results)
  cat("Accuracy:", round(m, 2), "\n\n")
  m
}
```

Start with all features

```{r}
features <- Zoo_train |> colnames() |> setdiff("type")
```

```{r}
subset <- backward.search(features, evaluator)
```

```{r}
subset <- forward.search(features, evaluator)
```

```{r}
subset <- best.first.search(features, evaluator)
```

```{r}
subset <- hill.climbing.search(features, evaluator)
```

### **Using Dummy Variables for Factors**

Dummy variables are binary variables (0 or 1) that represent the categories of a categorical variable. For each category, a corresponding dummy variable is created.

```{r}
tree_predator <- Zoo_train |> 
  rpart(predator ~ type, data = _)
rpart.plot(tree_predator, extra = 2, roundint = FALSE)
```

```{r}
Zoo_train_dummy <- as_tibble(class2ind(Zoo_train$type)) |> 
  mutate(across(everything(), as.factor)) |>
  add_column(predator = Zoo_train$predator)
Zoo_train_dummy
```

```{r}
tree_predator <- Zoo_train_dummy |> 
  rpart(predator ~ ., 
        data = _,
        control = rpart.control(minsplit = 2, cp = 0.01))
rpart.plot(tree_predator, roundint = FALSE)
```

```{r}
fit <- Zoo_train |> 
  train(predator ~ type, 
        data = _, 
        method = "rpart",
        control = rpart.control(minsplit = 2),
        tuneGrid = data.frame(cp = 0.01))
fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

## **Class Imbalance**

Classifiers have a hard time to learn from data where we have much more observations for one class (called the majority class). This is called the class imbalance problem.

```{r}
library(rpart)
library(rpart.plot)
data(Zoo, package="mlbench")
```

Class distribution

```{r}
ggplot(Zoo, aes(y = type)) + geom_bar()
```

To create an imbalanced problem, we want to decide if an animal is an reptile. First, we change the class variable to make it into a binary reptile/no reptile classification problem.

```{r}
Zoo_reptile <- Zoo |> 
  mutate(type = factor(Zoo$type == "reptile", 
                       levels = c(FALSE, TRUE),
                       labels = c("nonreptile", "reptile")))
```

```{r}
summary(Zoo_reptile)
```

```{r}
ggplot(Zoo_reptile, aes(y = type)) + geom_bar()
```

The bar chart to visualize the distribution of the "type" variable.

Create test and training data. I use here a 50/50 split to make sure that the test set has some samples of the rare reptile class.

```{r}
set.seed(1234)

inTrain <- createDataPartition(y = Zoo_reptile$type, p = .5, list = FALSE)
training_reptile <- Zoo_reptile |> slice(inTrain)
testing_reptile <- Zoo_reptile |> slice(-inTrain)
```

splits the "Zoo_reptile" dataset into a training dataset (training_reptile) and a testing dataset (testing_reptile) with a 50/50 split ratio.

### **Option 1: Use the Data As Is and Hope For The Best**

```{r}
fit <- training_reptile |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"))
```

```{r}
fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

The tree predicts everything as non-reptile. Have a look at the error on the test set.

```{r}
confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

### **Option 2: Balance Data With Resampling**

We use stratified sampling with replacement (to oversample the minority/positive class).

```{r}
library(sampling)
set.seed(1000) # for repeatability

id <- strata(training_reptile, stratanames = "type", size = c(50, 50), method = "srswr")
training_reptile_balanced <- training_reptile |> 
  slice(id$ID_unit)
table(training_reptile_balanced$type)
```

Here we are using 50 observations from each stratum.

```{r}
fit <- training_reptile_balanced |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"),
        control = rpart.control(minsplit = 5))

fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

Check on the unbalanced testing data by confusion matrix:

```{r}
confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

```{r}
id <- strata(training_reptile, stratanames = "type", size = c(50, 100), method = "srswr")
training_reptile_balanced <- training_reptile |> 
  slice(id$ID_unit)
table(training_reptile_balanced$type)
```

The stratum with "50" in the size parameter gets 50 randomly sampled observations, and the stratum with "100" gets 100 randomly sampled observations to create a balanced training dataset.

```{r}
fit <- training_reptile_balanced |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        trControl = trainControl(method = "cv"),
        control = rpart.control(minsplit = 5))

confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

### **Option 3: Build A Larger Tree and use Predicted Probabilities**

Augment the intricacy of the model, demanding a smaller dataset for node splitting. Additionally, I utilize AUC (Area Under the ROC Curve) as the metric for tuning. It's essential to define the two-class summary function. It's worth noting that the tree continues its efforts to enhance accuracy on the dataset rather than AUC. I've also activated class probabilities as I intend to make probability predictions at a later stage.

```{r}
fit <- training_reptile |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        tuneLength = 10,
        trControl = trainControl(method = "cv",
        classProbs = TRUE,  ## necessary for predict with type="prob"
        summaryFunction=twoClassSummary),  ## necessary for ROC
        metric = "ROC",
        control = rpart.control(minsplit = 3))
```

```{r}
fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

confusion matrix:

```{r}
confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

#### Create A Biased Classifier

```{r}
prob <- predict(fit, testing_reptile, type = "prob")
tail(prob)
```

Each row will contain the probabilities associated with each class, and you can see how confident the model is about its predictions for those particular observations.

```{r}
pred <- as.factor(ifelse(prob[,"reptile"]>=0.01, "reptile", "nonreptile"))

confusionMatrix(data = pred,
                ref = testing_reptile$type, positive = "reptile")
```

#### Plot the ROC Curve

Given our binary classification task and a classifier that predicts the likelihood of an observation being a yes, we can employ a Receiver Operating Characteristic (ROC) curve. This curve encompasses various cutoff thresholds for the predicted probabilities, which are then connected with a line. The area under this curve provides a single metric indicating the classifier's performance (the closer to one, the better).

```{r}
library("pROC")
r <- roc(testing_reptile$type == "reptile", prob[,"reptile"])
```

```{r}
r
```

```{r}
ggroc(r) + geom_abline(intercept = 1, slope = 1, color = "darkgrey")
```

An AUC-ROC score of 0.766 indicates that the model's performance is relatively good

### **Option 4: Use a Cost-Sensitive Classifier**

The implementation of CART in `rpart` can use a cost matrix for making splitting decisions (as parameter `loss`). The matrix has the form

TP FP FN TN

TP and TN have to be 0. We make FN very expensive (100).

```{r}
cost <- matrix(c(
  0,   1,
  100, 0
), byrow = TRUE, nrow = 2)
cost
```

```{r}
fit <- training_reptile |> 
  train(type ~ .,
        data = _,
        method = "rpart",
        parms = list(loss = cost),
        trControl = trainControl(method = "cv"))
```

```{r}
fit
```

```{r}
rpart.plot(fit$finalModel, extra = 2)
```

```{r}
confusionMatrix(data = predict(fit, testing_reptile),
                ref = testing_reptile$type, positive = "reptile")
```

# **Classification: Alternative Techniques**

## **Install packages**

```{r}
if(!require(pacman))
  install.packages("pacman")

pacman::p_load(
  C50,                # C5.0 Decision Trees and Rule-Based Models
  caret,              # Classification and Regression Training
  e1071,              # Misc Functions of the Department of Statistics (e1071), TU Wien
  keras,              # R Interface to 'Keras'
  kernlab,            # Kernel-Based Machine Learning Lab
  lattice,            # Trellis Graphics for R
  MASS,               # Support Functions and Datasets for Venables and Ripley's MASS
  mlbench,            # Machine Learning Benchmark Problems
  nnet,               # Feedforward Neural Networks and Multinomial Log-Linear Models
  palmerpenguins,     # Palmer Archipelago (Antarctica) Penguin Data
  party,              # A Laboratory for Recursive Partytioning
  partykit,           # A Toolkit for Recursive Partytioning
  randomForest,       # Breiman and Cutler's Random Forests for Classification and Regression
  rpart,              # Recursive partitioning models
  RWeka,              # R/Weka Interface
  scales,             # Scale Functions for Visualization
  tidymodels,         # Tidy machine learning framework
  tidyverse,          # Tidy data wrangling and visualization
  xgboost             # Extreme Gradient Boosting
)
```

Show fewer digits

```{r}
options(digits=3) # Controls how many decimal places are displayed
```

## **Training and Test Data**

We'll work with the Zoo dataset available in the R package mlbench (you might need to install it if you haven't already). This dataset comprises 17 variables, mostly logical, describing 101 animals. The data is structured as a data frame with 17 columns representing various characteristics such as hair, feathers, eggs, milk, and more (including attributes like predator, legs, and type). Optionally, we can convert the data frame into a tibble using the tidyverse framework.

```{r}
data(Zoo, package="mlbench")
Zoo <- as.data.frame(Zoo)
Zoo |> glimpse()
```

Test data is not used in the model building process and needs to be set aside purely for testing the model after it is completely built. Here I use 80% for training.

```{r}
set.seed(123)  # for reproducibility
inTrain <- createDataPartition(y = Zoo$type, p = .8)[[1]]
Zoo_train <- dplyr::slice(Zoo, inTrain)
Zoo_test <- dplyr::slice(Zoo, -inTrain)
```

## **Fitting Different Classification Models to the Training Data**

Create a fixed sampling scheme (10-folds) so we can compare the fitted models later.

```{r}
train_index <- createFolds(Zoo_train$type, k = 10)
```

### **Conditional Inference Tree (Decision Tree)**

Conditional Inference Trees is a different kind of decision tree that uses recursive partitioning of dependent variables based on the value of correlations.

```{r}
ctreeFit <- Zoo_train |> train(type ~ .,
  method = "ctree",
  data = _,
    tuneLength = 5,
    trControl = trainControl(method = "cv", indexOut = train_index))
ctreeFit
```

The conditional inference tree model performed very well in terms of accuracy and kappa, and the hyperparameter "mincriterion" was set to 0.99 to achieve this level of performance.

```{r}
plot(ctreeFit$finalModel)
```

### **C 4.5 Decision Tree**

The "C4.5" decision tree algorithm, also known as C5.0, is a widely used classification algorithm in machine learning. It was developed by Ross Quinlan and is an extension of the ID3 (Iterative Dichotomiser 3) algorithm. C4.5 is used for both classification and regression tasks.

```{r}
C45Fit <- Zoo_train |> train(type ~ .,
  method = "J48",
  data = _,
    tuneLength = 5,
    trControl = trainControl(method = "cv", indexOut = train_index))
C45Fit
```

The model with the highest Accuracy value was selected as the optimal model.The final values used for the model were **C = 0.133** and **M = 1**

```{r}
C45Fit$finalModel
```

### **K-Nearest Neighbors**

kNN uses Euclidean distance, so data should be standardized (scaled) first. Here legs are measured between 0 and 6 while all other variables are between 0 and 1. Scaling can be directly performed as preprocessing in train using the parameter preProcess = "scale".

```{r}
knnFit <- Zoo_train |> train(type ~ .,
  method = "knn",
  data = _,
  preProcess = "scale",
    tuneLength = 5,
  tuneGrid=data.frame(k = 1:10),
    trControl = trainControl(method = "cv", indexOut = train_index))
knnFit
```

KNN classification model using cross-validation for model evaluation. It explores different values of the "k" parameter and scales the data as part of preprocessing.

```{r}
knnFit$finalModel
```

### **PART (Rule-based classifier)**

PART stands for "Partial C 4.5," and it is an extension of the well-known C4.5 decision tree algorithm. PART is designed for classification tasks and is particularly useful when dealing with datasets that contain missing values or noisy data.

```{r}
rulesFit <- Zoo_train |> train(type ~ .,
  method = "PART",
  data = _,
  tuneLength = 5,
  trControl = trainControl(method = "cv", indexOut = train_index))
rulesFit
```

For each combination of "threshold" and "pruned" settings, we have given the accuracy and Kappa statistics. Here for all the cases it's 1. The final values used for the model were threshold = 0.5 and pruned = yes.

```{r}
rulesFit$finalModel
```

### **Linear Support Vector Machines**

Linear Support Vector Machines (SVM) are a type of supervised machine learning algorithm used for classification and regression tasks. In the context of classification, linear SVM aims to find the optimal hyperplane that best separates different classes in the feature space. This hyperplane is the one that maximizes the margin between the classes, making it a robust and effective classifier, especially in high-dimensional spaces.

```{r}
svmFit <- Zoo_train |> train(type ~.,
  method = "svmLinear",
  data = _,
    tuneLength = 5,
    trControl = trainControl(method = "cv", indexOut = train_index))
svmFit
```

The results indicate that the model achieved high accuracy (0.97) and perfect Kappa (0.97).

```{r}
svmFit$finalModel
```

### **Random Forest**

Random Forest is an ensemble learning method used for both classification and regression tasks. It operates by constructing a multitude of decision trees during training and outputs the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.

```{r}
randomForestFit <- Zoo_train |> train(type ~ .,
  method = "rf",
  data = _,
    tuneLength = 5,
    trControl = trainControl(method = "cv", indexOut = train_index))
randomForestFit
```

```{r}
randomForestFit$finalModel
```

### **Gradient Boosted Decision Trees (xgboost)**

XGBoost, short for eXtreme Gradient Boosting, is an optimized and scalable implementation of gradient boosting machines. It's a machine learning algorithm that belongs to the family of ensemble learning methods. Specifically, XGBoost is used for both classification and regression tasks, and it is known for its speed and performance.

```{r}
xgboostFit <- Zoo_train |> train(type ~ .,
  method = "xgbTree",
  data = _,
  tuneLength = 5,
  trControl = trainControl(method = "cv", indexOut = train_index),
  tuneGrid = expand.grid(
    nrounds = 20,
    max_depth = 3,
    colsample_bytree = .6,
    eta = 0.1,
    gamma=0,
    min_child_weight = 1,
    subsample = .5
  ))
xgboostFit
```

The results indicate that the model achieved very high accuracy (0.97) and Kappa (0.96).

```{r}
xgboostFit$finalModel
```

### **Artificial Neural Network**

Artificial Neural Networks (ANNs) are computational models inspired by the way biological neural networks in the human brain work. ANNs are used in machine learning and artificial intelligence for various tasks, including classification, regression, pattern recognition, and decision making.

```{r}
nnetFit <- Zoo_train |> train(type ~ .,
  method = "nnet",
  data = _,
    tuneLength = 5,
    trControl = trainControl(method = "cv", indexOut = train_index),
  trace = FALSE)
nnetFit
```

Different combinations of "size" and "decay" values are tested during hyperparameter tuning to find the combination that results in the best model performance. Accuracy was used to select the optimal model, and the final values used for the model are size = 3 and decay = 0.01.

```{r}
nnetFit$finalModel
```

## **Comparing Models**

Collect the performance metrics from the models trained on the same data.

```{r}
resamps <- resamples(list(
  ctree = ctreeFit,
  C45 = C45Fit,
  SVM = svmFit,
  KNN = knnFit,
  rules = rulesFit,
  randomForest = randomForestFit,
  xgboost = xgboostFit,
  NeuralNet = nnetFit
    ))
resamps
```

Calculate summary statistics

```{r}
summary(resamps)
```

The accuracy values range from 0.7 to 1.00 and Kappa values ranges from 0.7 to 1.000, showing majority of models are performing well.

```{r}
library(lattice)
bwplot(resamps, layout = c(3, 1))
```

Conduct an analysis to compare differences between models. This involves computing and testing all possible pairwise differences for each metric to determine if the differences are statistically significant. The default method includes Bonferroni correction for handling multiple comparisons. The resulting differences are displayed in the upper triangle, while corresponding p-values are presented in the lower triangle.

```{r}
difs <- diff(resamps)
difs
```

```{r}
summary(difs)
```

## **Applying the Chosen Model to the Test Data**

Most models do similarly well on the data. We choose here the random forest model.

```{r}
pr <- predict(randomForestFit, Zoo_test)
pr
```

Calculate the confusion matrix for the held-out test data.

```{r}
confusionMatrix(pr, reference = Zoo_test$type)
```

## **Comparing Decision Boundaries of Popular Classification Techniques**

Classifiers establish boundaries to distinguish between classes. Various classifiers generate distinct shapes of these boundaries; for instance, some are strictly linear. Consequently, specific classifiers might excel with particular datasets. On this page, we visualize the decision boundaries created by several widely used classification methods.

In the displayed plot, the decision boundary is represented by black lines, and the intensity of color indicates the classification confidence. This is achieved by evaluating the classifier at evenly spaced grid points. It's important to note that using a low resolution (to expedite evaluation) can create an illusion of small steps in the decision boundary, even if it is a straight line.

```{r}
library(scales)
library(tidyverse)
library(ggplot2)
library(caret)

decisionplot <- function(model, data, class_var, 
  predict_type = c("class", "prob"), resolution = 3 * 72) {
  # resolution is set to 72 dpi if the image is rendered  3 inches wide. 
  
  y <- data |> pull(class_var)
  x <- data |> dplyr::select(-all_of(class_var))
  
  # resubstitution accuracy
  prediction <- predict(model, x, type = predict_type[1])
  # LDA returns a list
  if(is.list(prediction)) prediction <- prediction$class
  prediction <- factor(prediction, levels = levels(y))
  
  cm <- confusionMatrix(data = prediction, 
                        reference = y)
  acc <- cm$overall["Accuracy"]
  
  # evaluate model on a grid
  r <- sapply(x[, 1:2], range, na.rm = TRUE)
  xs <- seq(r[1,1], r[2,1], length.out = resolution)
  ys <- seq(r[1,2], r[2,2], length.out = resolution)
  g <- cbind(rep(xs, each = resolution), rep(ys, time = resolution))
  colnames(g) <- colnames(r)
  g <- as_tibble(g)
  
  ### guess how to get class labels from predict
  ### (unfortunately not very consistent between models)
  cl <- predict(model, g, type = predict_type[1])
  
  # LDA returns a list
  prob <- NULL
  if(is.list(cl)) { 
    prob <- cl$posterior
    cl <- cl$class
  } else
    if(!is.na(predict_type[2]))
      try(prob <- predict(model, g, type = predict_type[2]))
  
  # we visualize the difference in probability/score between the 
  # winning class and the second best class.
  # don't use probability if predict for the classifier does not support it.
  max_prob <- 1
  if(!is.null(prob))
    try({
      max_prob <- t(apply(prob, MARGIN = 1, sort, decreasing = TRUE))
      max_prob <- max_prob[,1] - max_prob[,2]
    }, silent = TRUE) 
  
  cl <- factor(cl, levels = levels(y))
  
  g <- g |> add_column(prediction = cl, probability = max_prob)
  
  ggplot(g, mapping = aes(
    x = .data[[colnames(g)[1]]], y = .data[[colnames(g)[2]]])) +
    geom_raster(mapping = aes(fill = prediction, alpha = probability)) +
    geom_contour(mapping = aes(z = as.numeric(prediction)), 
      bins = length(levels(cl)), linewidth = .5, color = "black") +
    geom_point(data = data, mapping =  aes(
      x = .data[[colnames(data)[1]]], 
      y = .data[[colnames(data)[2]]],
      shape = .data[[class_var]]), alpha = .7) + 
    scale_alpha_continuous(range = c(0,1), limits = c(0,1), guide = "none") +  
    labs(subtitle = paste("Training accuracy:", round(acc, 2))) +
     theme_minimal(base_size = 14)
}
```

### **Penguins Dataset**

For easier visualization, we use two dimensions of the `penguins` dataset. Contour lines visualize the density like mountains on a map.

```{r}
set.seed(1000)
data("penguins")
penguins <- as_tibble(penguins) |>
  drop_na()

### Three classes 
### (note: MASS also has a select function which hides dplyr's select)
x <- penguins |> dplyr::select(bill_length_mm, bill_depth_mm, species)
x
```

```{r}
ggplot(x, aes(x = bill_length_mm, y = bill_depth_mm, fill = species)) +  
  stat_density_2d(geom = "polygon", aes(alpha = after_stat(level))) +
  geom_point() +
  theme_minimal(base_size = 14) +
  labs(x = "Bill length (mm)",
       y = "Bill depth (mm)",
       fill = "Species",
       alpha = "Density")
```

#### K-Nearest Neighbors Classifier

K-Nearest Neighbors (KNN) is a simple, instance-based, and non-parametric machine learning algorithm used for both classification and regression tasks. In classification, KNN predicts the class of a data point based on the classes of its nearest neighbors, where �k is a user-defined parameter specifying the number of neighbors to consider.

set the number of nearest neighbors to 1

```{r}
model <- x |> caret::knn3(species ~ ., data = _, k = 1)
decisionplot(model, x, class_var = "species") + 
  labs(title = "kNN (1 neighbor)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

set the number of nearest neighbors to 3

```{r}
model <- x |> caret::knn3(species ~ ., data = _, k = 3)
decisionplot(model, x, class_var = "species") + 
  labs(title = "kNN (3 neighbor)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

set the number of nearest neighbors to 9

```{r}
model <- x |> caret::knn3(species ~ ., data = _, k = 9)
decisionplot(model, x, class_var = "species") + 
  labs(title = "kNN (9 neighbor)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

#### Naive Bayes Classifier

Naive Bayes is a probabilistic machine learning algorithm based on Bayes' theorem. It is a simple and efficient classification technique that is particularly well-suited for text classification and spam filtering. Despite its simplicity, Naive Bayes often performs surprisingly well in practice, especially on tasks with high-dimensional feature spaces.

```{r}
model <- x |> e1071::naiveBayes(species ~ ., data = _)
decisionplot(model, x, class_var = "species", 
             predict_type = c("class", "raw")) + 
  labs(title = "Naive Bayes",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction") 
```

#### Linear Discriminant Analysis

Linear Discriminant Analysis (LDA) is a supervised machine learning algorithm used for classification and dimensionality reduction. It is particularly useful when dealing with multi-class classification problems and is based on statistical principles. LDA works by finding linear combinations of features that best separate different classes in the data.

```{r}
model <- x |> MASS::lda(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "LDA",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

#### Multinomial Logistic Regression (implemented in nnet)

Multinomial Logistic Regression, also known as Softmax Regression, is an extension of binary logistic regression to handle multi-class classification problems. In this method, the outcome variable can take more than two classes, and the algorithm predicts the probability of each class. The class with the highest probability is then assigned as the predicted class for a given input.

```{r}
model <- x |> nnet::multinom(species ~., data = _)
```

```{r}
decisionplot(model, x, class_var = "species") + 
  labs(title = "Multinomial Logistic Regression",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

#### Decision Trees

Decision Trees are versatile supervised machine learning algorithms used for both classification and regression tasks. They work by recursively partitioning the data into subsets based on the values of input features. Each partition is based on a decision rule learned from the training data, enabling the algorithm to make predictions for unseen or future data points.

```{r}
model <- x |> rpart::rpart(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "CART",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> rpart::rpart(species ~ ., data = _,
  control = rpart.control(cp = 0.001, minsplit = 1))
decisionplot(model, x, class_var = "species") + 
  labs(title = "CART (overfitting)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> C50::C5.0(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "C5.0",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> randomForest::randomForest(species ~ ., data = _)
decisionplot(model, x, class_var = "species") + 
  labs(title = "Random Forest",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

#### SVM

Support Vector Machines (SVM) is a powerful supervised machine learning algorithm used for both classification and regression tasks. SVM is particularly effective in high-dimensional spaces and is well-suited for tasks where the data has clear margins of separation between classes.

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "linear")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (linear kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "radial")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (radial kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "polynomial")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (polynomial kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <- x |> e1071::svm(species ~ ., data = _, kernel = "sigmoid")
decisionplot(model, x, class_var = "species") + 
  labs(title = "SVM (sigmoid kernel)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

#### Single Layer Feed-forward Neural Networks

A Single Layer Feed-forward Neural Network, often referred to as a Perceptron, is the simplest form of artificial neural networks. It consists of only one layer, the output layer, with no hidden layers. This basic neural network model can be used for binary classification tasks.

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 1, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (1 neuron)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

**`size`** specifies that the neural network should have how many hidden neurons in a single hidden layer.

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 2, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (2 neurons)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 4, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (4 neurons)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(species ~ ., data = _, size = 10, trace = FALSE)
decisionplot(model, x, class_var  = "species", 
  predict_type = c("class", "raw")) + 
  labs(title = "NN (10 neurons)",
       x = "Bill length (mm)",
       y = "Bill depth (mm)",
       shape = "Species",
       fill = "Prediction")
```

### **Circle Dataset**

```{r}
set.seed(1000)

x <- mlbench::mlbench.circle(500)
###x <- mlbench::mlbench.cassini(500)
###x <- mlbench::mlbench.spirals(500, sd = .1)
###x <- mlbench::mlbench.smiley(500)
x <- cbind(as.data.frame(x$x), factor(x$classes))
colnames(x) <- c("x", "y", "class")
x <- as_tibble(x)
x
```

```{r}
ggplot(x, aes(x = x, y = y, color = class)) + 
  geom_point() +
  theme_minimal(base_size = 14)
```

#### K-Nearest Neighbors Classifier

K-Nearest Neighbors (KNN) is a simple, instance-based, and non-parametric machine learning algorithm used for both classification and regression tasks. In classification, KNN predicts the class of a data point based on the classes of its nearest neighbors, where �k is a user-defined parameter specifying the number of neighbors to consider.

```{r}
model <- x |> caret::knn3(class ~ ., data = _, k = 1)
decisionplot(model, x, class_var = "class") + 
  labs(title = "kNN (1 neighbor)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> caret::knn3(class ~ ., data = _, k = 10)
decisionplot(model, x, class_var = "class") + 
  labs(title = "kNN (10 neighbor)",
       shape = "Class",
       fill = "Prediction")
```

#### Naive Bayes Classifier

Naive Bayes is a probabilistic machine learning algorithm based on Bayes' theorem. It is a simple and efficient classification technique that is particularly well-suited for text classification and spam filtering. Despite its simplicity, Naive Bayes often performs surprisingly well in practice, especially on tasks with high-dimensional feature spaces.

```{r}
model <- x |> e1071::naiveBayes(class ~ ., data = _)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class", "raw")) + 
  labs(title = "naive Bayes",
       shape = "Class",
       fill = "Prediction")
```

#### Linear Discriminant Analysis

Linear Discriminant Analysis (LDA) is a supervised machine learning algorithm used for classification and dimensionality reduction. It is particularly useful when dealing with multi-class classification problems and is based on statistical principles. LDA works by finding linear combinations of features that best separate different classes in the data.

```{r}
model <- x |> MASS::lda(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "LDA",
       shape = "Class",
       fill = "Prediction")
```

#### Logistic Regression (implemented in nnet)

Logistic Regression is a statistical method used for binary classification tasks, where the outcome variable has two classes. In the context of machine learning, logistic regression is also widely used for multi-class classification problems, using techniques like one-vs-rest (OvR) or one-vs-one (OvO) approaches. The logistic regression model predicts the probability that an instance belongs to a particular class.

```{r}
model <- x |> nnet::multinom(class ~., data = _)
```

```{r}
decisionplot(model, x, class_var = "class") + 
  labs(title = "Multinomial Logistic Regression",
       shape = "Class",
       fill = "Prediction")
```

#### Decision Trees

Decision Trees are versatile supervised machine learning algorithms used for both classification and regression tasks. They work by recursively partitioning the data into subsets based on the values of input features. Each partition is based on a decision rule learned from the training data, enabling the algorithm to make predictions for unseen or future data points.

```{r}
model <- x |> rpart::rpart(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "CART",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> rpart::rpart(class ~ ., data = _,
  control = rpart.control(cp = 0.001, minsplit = 1))
decisionplot(model, x, class_var = "class") + 
  labs(title = "CART (overfitting)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <- x |> C50::C5.0(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "C5.0",
       shape = "Class",
       fill = "Prediction")
```

```{r}
library(randomForest)
model <- x |> randomForest(class ~ ., data = _)
decisionplot(model, x, class_var = "class") + 
  labs(title = "Random Forest",
       shape = "Class",
       fill = "Prediction")
```

#### SVM

Support Vector Machines (SVM) is a powerful supervised machine learning algorithm used for both classification and regression tasks. SVM is particularly effective in high-dimensional spaces and is well-suited for tasks where the data has clear margins of separation between classes.

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "linear")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (linear kernel)",
       shape = "Class",
       fill = "Prediction")
```

The kernel is radially symmetric, and the decision boundary is determined by the distance between data points. Data points closer to the support vectors have a stronger influence on the classification.

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "radial")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (radial kernel)",
       shape = "Class",
       fill = "Prediction")
```

The polynomial kernel is a popular choice in Support Vector Machines (SVM) for handling non-linear data by implicitly mapping it into a higher-dimensional space. It is one of the kernel functions used to create non-linear decision boundaries.

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "polynomial")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (polynomial kernel)",
       shape = "Class",
       fill = "Prediction")
```

Similar to other kernel functions, the sigmoid kernel is an example of the kernel trick, allowing SVM to implicitly map data into a higher-dimensional space where it becomes linearly separable.

```{r}
model <- x |> e1071::svm(class ~ ., data = _, kernel = "sigmoid")
decisionplot(model, x, class_var = "class") + 
  labs(title = "SVM (sigmoid kernel)",
       shape = "Class",
       fill = "Prediction")
```

#### Single Layer Feed-forward Neural Networks

A Single Layer Feed-forward Neural Network, often referred to as a Perceptron, is the simplest form of artificial neural networks. It consists of only one layer, the output layer, with no hidden layers. This basic neural network model can be used for binary classification tasks.

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 1, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (1 neuron)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 2, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (2 neurons)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 4, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (4 neurons)",
       shape = "Class",
       fill = "Prediction")
```

```{r}
model <-x |> nnet::nnet(class ~ ., data = _, size = 10, trace = FALSE)
decisionplot(model, x, class_var = "class", 
  predict_type = c("class")) + 
  labs(title = "NN (10 neurons)",
       shape = "Class",
       fill = "Prediction")
```
